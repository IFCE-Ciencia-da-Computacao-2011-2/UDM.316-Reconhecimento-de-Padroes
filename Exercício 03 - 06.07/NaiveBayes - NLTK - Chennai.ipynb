{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseado em \n",
    "\n",
    "* https://gist.github.com/billy-yuan/0fe85405cb24c61ada5516165206b9f3\n",
    "* http://www.nltk.org/book/ch06.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_name</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accord Metropolitan</td>\n",
       "      <td>Excellent comfortableness during stay</td>\n",
       "      <td>Its really nice place to stay especially for b...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accord Metropolitan</td>\n",
       "      <td>Not too comfortable</td>\n",
       "      <td>It seems that hotel does not check the basic a...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accord Metropolitan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worst hotel I have ever encountered. I will ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accord Metropolitan</td>\n",
       "      <td>Best hotel</td>\n",
       "      <td>Had a good time in this hotel and the staff Ku...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accord Metropolitan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good hotel and staff Veg food good non veg bre...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hotel_name                           Review_Title  \\\n",
       "0  Accord Metropolitan  Excellent comfortableness during stay   \n",
       "1  Accord Metropolitan                    Not too comfortable   \n",
       "2  Accord Metropolitan                                    NaN   \n",
       "3  Accord Metropolitan                             Best hotel   \n",
       "4  Accord Metropolitan                                    NaN   \n",
       "\n",
       "                                         Review_Text  Sentiment  \\\n",
       "0  Its really nice place to stay especially for b...          3   \n",
       "1  It seems that hotel does not check the basic a...          1   \n",
       "2  Worst hotel I have ever encountered. I will ne...          1   \n",
       "3  Had a good time in this hotel and the staff Ku...          3   \n",
       "4  good hotel and staff Veg food good non veg bre...          3   \n",
       "\n",
       "   Rating_Percentage  \n",
       "0                100  \n",
       "1                 20  \n",
       "2                 20  \n",
       "3                100  \n",
       "4                100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chennai = pd.read_csv('chennai.csv', sep=';')\n",
    "chennai.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "\n",
    "### Preparador para treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesPreparator(object):\n",
    "    \n",
    "    def __init__(self, sentiments, descriptions):\n",
    "        self._translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "        self.sentiments = sentiments\n",
    "        self.descriptions = descriptions\n",
    "        \n",
    "        self.features = list(zip(self.count_words(descriptions), sentiments))\n",
    "\n",
    "    def count_words(self, descriptions):\n",
    "        '''\n",
    "        :return Dict of used words with the total size used\n",
    "        '''\n",
    "        return [dict(Counter(self.decode(description))) for description in descriptions]\n",
    "\n",
    "    def decode(self, text):\n",
    "        '''\n",
    "        Given a text, removes your punctuation and split the words\n",
    "        '''\n",
    "        text = text.translate(self._translator)\n",
    "        return nltk.word_tokenize(text)\n",
    "    \n",
    "        #is_adjective = lambda tag: tag[:2] == 'JJ'\n",
    "        #return [word for (word, tag) in nltk.pos_tag(text) if is_adjective(tag)]\n",
    "\n",
    "    def split(self, test_size=0.2, random_state=None):\n",
    "        '''\n",
    "        Split data into train and test data\n",
    "        '''\n",
    "        return train_test_split(self.features, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilitário para medir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Accuracy(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def mensurate(classifier, training_set, test_set):\n",
    "        print(\"TRAIN SET\")\n",
    "        print('Train base', nltk.classify.accuracy(classifier, train_set))\n",
    "        Accuracy.mensurate_by_class(classifier, train_set)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print(\"TEST SET\")\n",
    "        print('Test base', nltk.classify.accuracy(classifier, test_set))\n",
    "        Accuracy.mensurate_by_class(classifier, test_set)\n",
    "\n",
    "    @staticmethod\n",
    "    def mensurate_by_class(classifier, elements):\n",
    "        d = defaultdict(list)\n",
    "\n",
    "        for test in elements:\n",
    "            d[test[1]].append(test)\n",
    "\n",
    "        for key in d.keys():\n",
    "            print(' - Class', key, ':', nltk.classify.accuracy(classifier, d[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   Worst = 1                   1 : 3      =     39.3 : 1.0\n",
      "                  Shower = 1                   1 : 3      =     31.5 : 1.0\n",
      "                    even = 2                   1 : 3      =     31.4 : 1.0\n",
      "                      no = 3                   1 : 3      =     31.4 : 1.0\n",
      "                   phone = 1                   1 : 3      =     28.5 : 1.0\n",
      "                   worst = 1                   1 : 3      =     28.4 : 1.0\n",
      "                   badly = 1                   1 : 3      =     27.6 : 1.0\n",
      "                 wouldnt = 1                   1 : 3      =     26.7 : 1.0\n",
      "                  linens = 1                   1 : 3      =     26.7 : 1.0\n",
      "                 privacy = 1                   1 : 3      =     26.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "descriptions = chennai['Review_Text']\n",
    "sentiments = chennai['Sentiment']\n",
    "\n",
    "train_set, test_set = NaiveBayesPreparator(sentiments, descriptions).split(random_state=128)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET\n",
      "Train base 0.86392239119\n",
      " - Class 1 : 0.936842105263\n",
      " - Class 2 : 0.899096385542\n",
      " - Class 3 : 0.845487364621\n",
      "\n",
      "TEST SET\n",
      "Test base 0.759958071279\n",
      " - Class 1 : 0.728971962617\n",
      " - Class 2 : 0.627118644068\n",
      " - Class 3 : 0.8\n"
     ]
    }
   ],
   "source": [
    "Accuracy.mensurate(classifier, train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros métodos\n",
    "\n",
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              unpleasant = 1                   1 : 3      =     26.7 : 1.0\n",
      "                   dirty = 1                   1 : 3      =     25.1 : 1.0\n",
      "                   worst = 1                   1 : 3      =     25.1 : 1.0\n",
      "                 cramped = 1                   1 : 3      =     21.8 : 1.0\n",
      "                    star = 1                   1 : 3      =     21.8 : 1.0\n",
      "                terrible = 1                   1 : 3      =     21.8 : 1.0\n",
      "            disappointed = 1                   1 : 3      =     21.8 : 1.0\n",
      "                pathetic = 1                   1 : 3      =     21.8 : 1.0\n",
      "                    torn = 1                   1 : 3      =     21.8 : 1.0\n",
      "                  hectic = 1                   1 : 3      =     17.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayesPreparatorBagOfWords(NaiveBayesPreparator):\n",
    "\n",
    "    def __init__(self, sentiments, descriptions):\n",
    "        self._all_words = self._calcule_all_words(descriptions)\n",
    "\n",
    "        super(NaiveBayesPreparatorBagOfWords, self).__init__(sentiments, descriptions)\n",
    "        \n",
    "    def _calcule_all_words(self, descriptions):\n",
    "        all_words = set()\n",
    "\n",
    "        for description in descriptions:\n",
    "            all_words |= set(decode_string(description))\n",
    "\n",
    "        return all_words\n",
    "\n",
    "    def count_words(self, descriptions):\n",
    "        def make(words):\n",
    "            counter = Counter(words)\n",
    "            return {k: counter[k] if k in words else 0 for k in self._all_words}\n",
    "\n",
    "        return [make(decode_string(description)) for description in descriptions]\n",
    "\n",
    "# --------------------\n",
    "\n",
    "train_set, test_set = NaiveBayesPreparatorBagOfWords(sentiments, descriptions).split(random_state=128)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET\n",
      "Train base 0.842160461458\n",
      " - Class 1 : 0.565789473684\n",
      " - Class 2 : 0.48343373494\n",
      " - Class 3 : 0.966064981949\n",
      "\n",
      "TEST SET\n",
      "Test base 0.759958071279\n",
      " - Class 1 : 0.336448598131\n",
      " - Class 2 : 0.310734463277\n",
      " - Class 3 : 0.946268656716\n"
     ]
    }
   ],
   "source": [
    "Accuracy.mensurate(classifier, train_set, test_set)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
